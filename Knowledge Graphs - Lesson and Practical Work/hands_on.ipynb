{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Embedding with TorchKGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will explore how to train a knowledge graph embedding model to perform link prediction in biological knowledge graphs.\n",
    "\n",
    "We will consider a knowledge graph composed of nodes representing \"genes/proteins,\" \"diseases,\" and \"drugs,\" and containing interactions such as \"drug-protein,\" \"disease-protein,\" and \"drug-disease.\" Our goal will be to predict new interactions of these types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we need to set up a conda environment that will contain the necessary libraries. Create the conda environment with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "conda create --name torch_pyg python=3.10\n",
    "conda activate torch_pyg\n",
    "pip install torch\n",
    "pip install torchkge\n",
    "pip install pandas matplotlib numpy pyyaml tqdm\n",
    "pip install pytorch-ignite\n",
    "pip install ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is stored in `TSV` format. Let's start by loading the file using the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this dataframe, we can instantiate a knowledge graph using [the `KnowledgeGraph` class from the TorchKGE library](https://torchkge.readthedocs.io/en/latest/reference/data.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the KnowledgeGraph class. What does `ent2ix` and `rel2ix` contains? How many entities and relations are contained in the KG? What are the methods associated to the KG class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the KG into a training set, a validation set and a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the training, validation and test sets in KGE? Why do we need such sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciating the KGE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a [model implemented in TorchKGE](https://torchkge.readthedocs.io/en/latest/reference/models.html). What hyperparameters do you need to define? Instanciate the chosen model with is corresponding parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the [loss function to train the model](https://torchkge.readthedocs.io/en/latest/reference/utils.html#losses).\n",
    "For Translational Models, the loss should be a MarginLoss. For Bilinear models, the loss should be a BinaryCrossEntropyLoss. Depending on the chosen loss, do you need to define new hyperparameters? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining an optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is an Optimizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Check the documentation of the [Adam optimize from Torch](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) and instanciate one. Which hyperparameters do you need to define ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a Negative Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Negative Sampling in KGE? Check [TorchKGE's documentation on negative sampling](https://torchkge.readthedocs.io/en/latest/reference/sampling.html), and check the various implementations available. What is the difference between those samplers? Chose one and instanciate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Defining a Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A learning rate scheduler is a tool that adjusts the learning rate during training to improve model convergence and performance. It typically decreases the learning rate over time or based on certain conditions, helping the model settle into an optimal solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A learning rate scheduler adjusts the learning rate during training, with many types available to suit different training needs. Here, we focus on [`lr_scheduler.CosineAnnealingWarmRestarts`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html), which gradually decreases the learning rate following a cosine curve, then \"restarts\" it at a higher rate periodically to allow the model to explore new solutions and avoid local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciating a Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, we have defined:\n",
    "* the KGE model\n",
    "* an optimizer\n",
    "* a negative sampler\n",
    "* (optionnally) a learning rate scheduler\n",
    "\n",
    "Now, we need to define the trainning hyperparameters:\n",
    "* number of training epochs\n",
    "* training batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchKGE proposes a [`DataLoader`](https://github.com/torchkge-team/torchkge/blob/master/torchkge/utils/data.py) to read and pass the data from the training set to the model. It takes as input:\n",
    "* the training KG\n",
    "* the batch size for loading the data in batches\n",
    "\n",
    "Instanciate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the function for processing batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have defined the DataLoader, we need to define the operations to perform on each batch. For this, we will use an [`Engine`](https://pytorch.org/ignite/generated/ignite.engine.engine.Engine.html#ignite.engine.engine.Engine) from Pytorch-Ignite.\n",
    "\n",
    "\n",
    "In PyTorch-Ignite, an `Engine` is a core component used to abstract and manage the process of training or evaluating a model, making it easier to handle the loop over data batches and implement complex training workflows. The `Engine` runs a given `process_function`, which defines the specific steps to perform on each batch. \n",
    "\n",
    "With `Engine`, you can also attach event handlers at specific stages in the loop, like at the beginning or end of an epoch or after processing each batch. This enables you to incorporate logging, metrics, scheduling, and other functionalities in a structured way, making it highly flexible for building custom training and evaluation pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define the function for processing a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(engine, batch):\n",
    "\n",
    "    # Unpack the batch into head, tail, and relation\n",
    "    h, t, r = batch[0], batch[1], batch[2]\n",
    "    \n",
    "    # Generate corrupted (negative) samples using the sampler\n",
    "    n_h, n_t = sampler.corrupt_batch(h, t, r)\n",
    "\n",
    "    # Clear previous gradients in the optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate the loss using positive and negative triplets\n",
    "    pos, neg = model(h, t, r, n_h, n_t)\n",
    "    loss = criterion(pos, neg)\n",
    "    loss.backward()  # Perform backpropagation to compute gradients\n",
    "    \n",
    "    # Update model parameters with the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Normalize model parameters \n",
    "    model.normalize_parameters()\n",
    "\n",
    "    # Return the loss value for this batch\n",
    "    return loss.item()\n",
    "\n",
    "# Attaching the process_batch function to the training Engine\n",
    "trainer = Engine(process_batch)\n",
    "\n",
    "# Attach a running average of the loss to the trainer for tracking average loss over time\n",
    "RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss_ra')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `process_batch` function defines a single training step, where it processes a batch of data to train a knowledge graph embedding model. First, it takes a batch containing head (`h`), tail (`t`), and relation (`r`) entities and generates corrupted (negative) examples (`n_h`, `n_t`) using the `corrupt_batch` function from our defined negative sampler. It then clears the gradients in the optimizer (`optimizer.zero_grad()`), calculates the loss using both positive and negative triplets (`pos` and `neg`) with the specified criterion, and performs backpropagation (`loss.backward()`) to compute gradients. Afterward, the optimizer updates the model parameters (`optimizer.step()`), and the model parameters are normalized (`model.normalize_parameters()`). Finally, the function returns the loss for this batch.\n",
    "\n",
    "The line `RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss_ra')` serves to calculate a smoothed, running average of the loss over batches during training. This running average is attached to the `trainer` engine with name `loss_ra`. This running average will be accessible after each epoch with `trainer.state.metrics['loss_ra']`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at [TorchKGE's documentation for models](https://torchkge.readthedocs.io/en/latest/reference/models.html), and explain why we run `pos, neg = model(h, t, r, n_h, n_t)` in the process_batch function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at [TorchKGE's documentation for losses](https://torchkge.readthedocs.io/en/latest/reference/utils.html#losses), and explain why we run `loss = criterion(pos, neg)` in the process_batch function and what is the score obtained at this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining event handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the `trainer` engine to process data batches and compute the loss. Now, we can attach **events** to our `trainer` engine. [Various events can be included at various steps of the training](https://pytorch.org/ignite/generated/ignite.engine.events.Events.html), depending on the user's needs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Events are defined as follow:\n",
    "\n",
    "```\n",
    "@trainer.on(<Event-type>)\n",
    "def func(engine):\n",
    "    # DO STUFF\n",
    "    \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line, `@trainer.on(<Event-type>)`, is a **decorator** in PyTorch-Ignite that registers an event handler to execute a specific function at the end of each epoch during training. Here’s how it works:\n",
    "\n",
    "1. `@trainer.on`: This decorator attaches the function defined immediately below it to the `trainer` engine.\n",
    "\n",
    "2. [`<Event-type>`](https://pytorch.org/ignite/generated/ignite.engine.events.Events.html): This is the specific event, such as the end of an epoch (i.e., one complete pass through the dataset), that will trigger the function.\n",
    "\n",
    "When applied, any function defined directly below `@trainer.on(<Event-type>)` will be executed each time `<Event-type>` occurs. This setup allows for performing actions like logging, validation, saving model checkpoints, or adjusting learning rates during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an event handler triggered at the end of each epoch to write the training metrics into a csv file. This should include the epoch number and the loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Optional):** If you have defined a CosineAnnealing learning rate scheduler, you need to define an event handler that updates the scheduler after each epoch is complete. To update a scheduler, you can use `scheduler.step()`.  Additionally, you can modify the handler defined above in order to also record the learning rate used at each epoch using `optimizer.param_groups[0]['lr']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def update_scheduler(engine):\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sum up:\n",
    "* we have defined a KGE model, an optimizer and created the Engine to process the data and train the model\n",
    "* we have defined a data loader to send the data to the model\n",
    "* we have defined an event to keep track of the loss value through the training process\n",
    "\n",
    "We are ready to start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(train_iterator, max_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the training metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training metrics file and plot the training loss evolution across training epochs. What do you think? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def plot_loss(df):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(df[0], df[1], label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.show()\n",
    "\n",
    "df = pd.read_csv('training_metrics.csv', header=None)\n",
    "plot_loss(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchKGE provides with [a class for Link Prediction evaluation](https://torchkge.readthedocs.io/en/latest/tutorials/evaluation.html). Use it to evaluate the performances of your trained model to predict relationships from the test set and interpret the results. What is the MRR? Hit@10?\n",
    "\n",
    "Note: you need to put your model on evaluation mode with `model.eval()` before running the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infering new interactions in the KG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our embedding model and have an idea of it's performances on predicting interactions from the test set, we can start using it to infer novel associations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchKGE provides with a [class for infering a missing entity given a head (or a tail) and a relation](https://torchkge.readthedocs.io/en/latest/reference/inference.html#entity-inference).\n",
    "\n",
    "However, the original implementation form TorchKGE suffers an issue with the evaluate function. Use the following implementation instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import empty, tensor\n",
    "from tqdm import tqdm  \n",
    "from torchkge.utils import filter_scores\n",
    "from torchkge.utils.data import get_n_batches\n",
    "import torch\n",
    "\n",
    "class DataLoader_:\n",
    "    \"\"\"This class is inspired from :class:`torch.utils.dataloader.DataLoader`.\n",
    "    It is however way simpler.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, a, b, batch_size, use_cuda=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            Size of the required batches.\n",
    "        use_cuda: str (opt, default = None)\n",
    "            Can be either None (no use of cuda at all), 'all' to move all the\n",
    "            dataset to cuda and then split in batches or 'batch' to simply move\n",
    "            the batches to cuda before they are returned.\n",
    "        \"\"\"\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if use_cuda is not None and use_cuda == 'all':\n",
    "            self.a = self.a.cuda()\n",
    "            self.b = self.b.cuda()\n",
    "\n",
    "    def __len__(self):\n",
    "        return get_n_batches(len(self.a), self.batch_size)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return _DataLoaderIter(self)\n",
    "\n",
    "\n",
    "class _DataLoaderIter:\n",
    "    def __init__(self, loader):\n",
    "        self.a = loader.a\n",
    "        self.b = loader.b\n",
    "\n",
    "        self.use_cuda = loader.use_cuda\n",
    "        self.batch_size = loader.batch_size\n",
    "\n",
    "        self.n_batches = get_n_batches(len(self.a), self.batch_size)\n",
    "        self.current_batch = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_batch == self.n_batches:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            i = self.current_batch\n",
    "            self.current_batch += 1\n",
    "\n",
    "            tmp_a = self.a[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "            tmp_b = self.b[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "\n",
    "            if self.use_cuda is not None and self.use_cuda == 'batch':\n",
    "                return tmp_a.cuda(), tmp_b.cuda()\n",
    "            else:\n",
    "                return tmp_a, tmp_b\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "\n",
    "class EntityInference(object):\n",
    "    \"\"\"Use trained embedding model to infer missing entities in triples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: torchkge.models.interfaces.Model\n",
    "        Embedding model inheriting from the right interface.\n",
    "    known_entities: `torch.Tensor`, shape: (n_facts), dtype: `torch.long`\n",
    "        List of the indices of known entities.\n",
    "    known_relations: `torch.Tensor`, shape: (n_facts), dtype: `torch.long`\n",
    "        List of the indices of known relations.\n",
    "    top_k: int\n",
    "        Indicates the number of top predictions to return.\n",
    "    missing: str\n",
    "        String indicating if the missing entities are the heads or the tails.\n",
    "    dictionary: dict, optional (default=None)\n",
    "        Dictionary of possible heads or tails (depending on the value of `missing`).\n",
    "        It is used to filter predictions that are known to be True in the training set\n",
    "        in order to return only new facts.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    predictions: `torch.Tensor`, shape: (n_facts, self.top_k), dtype: `torch.long`\n",
    "        List of the indices of predicted entities for each test fact.\n",
    "    scores: `torch.Tensor`, shape: (n_facts, self.top_k), dtype: `torch.float`\n",
    "        List of the scores of resulting triples for each test fact.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, known_entities, known_relations, top_k=1, missing='tails', dictionary=None):\n",
    "        assert missing in ['heads', 'tails'], \"missing entity should either be 'heads' or 'tails'\"\n",
    "        \n",
    "        self.model = model\n",
    "        self.known_entities = known_entities\n",
    "        self.known_relations = known_relations\n",
    "        self.missing = missing\n",
    "        self.top_k = top_k\n",
    "        self.dictionary = dictionary\n",
    "\n",
    "        self.predictions = empty(size=(len(known_entities), top_k), dtype=torch.long)\n",
    "        self.scores = empty(size=(len(known_entities), top_k), dtype=torch.float)\n",
    "\n",
    "    def evaluate(self, b_size, verbose=True):\n",
    "        use_cuda = next(self.model.parameters()).is_cuda\n",
    "\n",
    "        if use_cuda:\n",
    "            dataloader = DataLoader_(self.known_entities, self.known_relations, batch_size=b_size, use_cuda='batch')\n",
    "            self.predictions = self.predictions.cuda()\n",
    "            self.scores = self.scores.cuda()\n",
    "        else:\n",
    "            dataloader = DataLoader_(self.known_entities, self.known_relations, batch_size=b_size)\n",
    "\n",
    "        for i, batch in tqdm(enumerate(dataloader), total=len(dataloader),\n",
    "                             unit='batch', disable=(not verbose),\n",
    "                             desc='Inference'):\n",
    "            known_ents, known_rels = batch[0], batch[1]\n",
    "            \n",
    "            if self.missing == 'heads':\n",
    "                _, t_emb, rel_emb, candidates = self.model.inference_prepare_candidates(\n",
    "                    tensor([]).long(), known_ents, known_rels, entities=True\n",
    "                )\n",
    "                scores = self.model.inference_scoring_function(candidates, t_emb, rel_emb)\n",
    "            else:\n",
    "                h_emb, _, rel_emb, candidates = self.model.inference_prepare_candidates(\n",
    "                    known_ents, tensor([]).long(), known_rels, entities=True\n",
    "                )\n",
    "                scores = self.model.inference_scoring_function(h_emb, candidates, rel_emb)\n",
    "\n",
    "            if self.dictionary is not None:\n",
    "                scores = filter_scores(scores, self.dictionary, known_ents, known_rels, None)\n",
    "\n",
    "            scores, indices = scores.sort(descending=True)\n",
    "\n",
    "            start_index = i * b_size\n",
    "            end_index = min((i + 1) * b_size, self.predictions.size(0))\n",
    "            \n",
    "            self.predictions[start_index:end_index, :self.top_k] = indices[:end_index - start_index, :self.top_k]\n",
    "            self.scores[start_index:end_index, :self.top_k] = scores[:end_index - start_index, :self.top_k]\n",
    "\n",
    "        if use_cuda:\n",
    "            self.predictions = self.predictions.cpu()\n",
    "            self.scores = self.scores.cpu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define one or several incomplete triplets for which you want to predict the missing head or tail. Instanciate the corresponding `EntityInference` class and run the inference process with `.evaluate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransEModel(emb_dim, n_entities, n_relations, dissimilarity_type=dissimilarity_type)\n",
    "criterion = MarginLoss(margin)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "sampler = UniformNegativeSampler(kg_train, kg_val=kg_val, kg_test=kg_test, n_neg=5)\n",
    "train_iterator = DataLoader(kg_train, batch_size)\n",
    "trainer = Engine(process_batch)\n",
    "RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss_ra')\n",
    "\n",
    "if os.path.exists('training_metrics_with_validation.csv'):\n",
    "    os.remove('training_metrics_with_validation.csv')\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=10))\n",
    "def evaluate(engine):\n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_mrr = link_pred(model, kg_val, 32) \n",
    "    engine.state.metrics['val_mrr'] = val_mrr \n",
    "\n",
    "    model.train()  # Put the model back in training mode\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_metrics_to_csv(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    train_loss = engine.state.metrics['loss_ra']\n",
    "    if 'val_mrr' in engine.state.metrics.keys():\n",
    "        mrr = engine.state.metrics['val_mrr']\n",
    "    else:\n",
    "        mrr = 0\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    with open('training_metrics_with_validation.csv', mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([epoch, train_loss, mrr, lr])\n",
    "    print(f\"Epoch: {epoch} ; Loss: {train_loss} ; Val MRR: {mrr}, LR: {optimizer.param_groups[0]['lr']}\")\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def update_scheduler(engine):\n",
    "    scheduler.step()\n",
    "    \n",
    "trainer.run(train_iterator, max_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the results. What are the heads or tails predicted for your incomplete triplets? How are the scores computed? Are the scores convincing? The higher the better or the lower the better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a KGE model with a validation set for Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the training procedure we implemented does not make use of the validation set. In the following part, we will include a procedure to evaluate the link prediction on the validation set during the training. **The goal will be to evaluate the training not on the loss value, but on the prediction of interactions from the validation set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an event handler that evaluates the link prediction on the validation set at the end of each epoch. Adapt the training metric tracking function to include the MRR on the validation set on each epoch, and rerun the whole training procedure. You can store the MRR score in `engine.state.metrics['val_mrr']` to acess it in the logging metrics function. Don't forget to switch the model from training mode to evaluation mode with `model.eval()` and from evaluation mode to training mode with `model.train()` when necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nottice how evaluation is computationally intensive, making the whole training quite long...\n",
    "\n",
    "Modify your code so that the evaluation is done only every 10 epochs instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is it better to use link prediction evaluation on the validation set instead of tracking the loss only?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers here: ..............**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss and the MRR over epochs and analyse the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, you may notice the MRR decreasing after a certain number of epochs. If this happens, you could end up with a model that, by the last epoch, performs worse on the validation MRR compared to its performance a few epochs earlier. To ensure that you keep the best model in terms of MRR on the validation set, it’s essential to save the model whenever it reaches its highest score. You can achieve this using [`ModelCheckpoint` from `ignite.handlers`](https://pytorch.org/ignite/generated/ignite.handlers.checkpoint.ModelCheckpoint.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how they work:\n",
    "\n",
    "```\n",
    "checkpoint_best_handler = ModelCheckpoint(\n",
    "    dirname=checkpoint_dir,                 # Saving directory\n",
    "    filename_prefix='best_model',           # Filename prefix\n",
    "    n_saved=N,                              # Number of models to save (to keep the N best models)\n",
    "    score_function=function_to_call,        # Function that returns the score of the model\n",
    "    score_name='val_mrr',                   # Name of the score\n",
    "    require_empty=False,                    # Should the saving directory be empty?\n",
    "    create_dir=True,                        # Create the saving directory if it does not exists\n",
    "    atomic=True                             # Ensure the file is not damaged\n",
    ")\n",
    "```\n",
    "\n",
    "A checkpoint handler can be added to the training procedure with: \n",
    "\n",
    "```\n",
    "trainer.add_event_handler(\n",
    "    Events.EPOCH_COMPLETED,\n",
    "    checkpoint_best_handler,\n",
    "    {'model': model}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `score_function` to pass to the checkpoint handler is a function that should return the current value of the performance metric you want to track. For instance, if you are interested into saving the model with the best MRR, the score_function should be a function that takes an engine as input and returns the current MRR as output. \n",
    "\n",
    "Define the score function, create the checkpoint handler, and add the corresponding event handler to the training pocedure. Then rerun the training. Since we are only performing the validation evaluation every 10 epochs, how often should the checkpoint handler be launched?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the best model for evaluating on the test dataset and for infering new triplets in the KG! Checkpoints can be loaded with `torch.load(file)`. Once your checkpoint is loaded, you can use `model.load_state_dict(checkpoint)` to load the state of your best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your best model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer new triples with your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To go further: a few ideas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training can take a long time. Take a look at [`EarlyStopping` in ignite](https://pytorch.org/ignite/v0.5.1/generated/ignite.handlers.early_stopping.EarlyStopping.html) and try to add an early stopping mechanism to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function to evaluate the link prediction on each relationship type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the node embeddings and visualize the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model on triplet classification instead of link prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with new models, and perform a benchmark of the best embedding models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
